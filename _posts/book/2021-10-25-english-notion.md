---
layout: post
title: 英语表述
category: 读书
tag: React
keywords: notes
---

## 表述

1. For each UAP, we evaluate its fooling rate on the model it was generated from (white-box attack) and on the three remaining models (transfer attack).
2. Our results show that models trained on Stylized-ImageNet are still **as vulnerable to** these UAPs **as** models trained on ImageNet.
3. For transfer attacks, where the UAP is generated from a model different from the evaluated one, the fooling rate consistently rises for " > 4.
4. Particularly, in case of critical applications that involve safety and security, reliable models need to be deployed to stand against the strong adversarial attacks. Thus, the effect of these structured perturbations has to be studied thoroughly in order to develop dependable machine learning systems.  需要研究对抗样本的原因
5. We train G in order to be able to generate the UAPs that can fool the target classifier over the underlying data distribution.
6. Hence, diagonal entries denote the white-box adversarial attacks and the off diagonal entries denote the black-box attacks.
7. It computes the gradient of the loss function with respect to pixels, and moves a single step based on the sign of the gradient.
8. To verify this latter claim
9. universal perturbations computed for the VGG-19 network have a fooling ratio above 53% for all other tested architectures.
10. Adversarial samples also possess the characteristic of transferability, which means adversarial sample generated for attacking one model could also mislead another model.
11. In this paper we present the first comprehensive evaluation of transferability of evasion and poisoning availability attacks,
12. as formulated in [42] and in follow-up work (e.g., [33]).
13. It is not difficult to see that， for  ...
14. In Fig. 6a we report the mean test error at e=1 for each target model against the size of its input gradients (S, averaged on the test samples and on the 10 runs).
15. A visual **inspection** of the poisoning digits  中毒数字的目视检查
16. The value in the i-th row and j-th column of each heatmap matrix is the proportion of the adversarial examples successfully transferred to target model j out of all adversarial examples generated by source model i (including both successful and failed attacks on the source model). 混淆矩阵的解释
17. In order to assess texture and shape biases, we conducted six major experiments **along with** three control experiments, which are described in the Appendix.
18. more fine-grained statement 
19. We view bridging this gap as an interesting direction for future work.

## 词汇

1. image-agnostic 图像不可知
2. proportional adj. 比例的, 成比例的  the performance of the resulting perturbation is proportional to the available training data.
3. adulterate  vt. (尤指食物)掺假, <废>奸污，诱奸 ,adj. 掺杂的，掺假的；不纯的 ,通奸的，犯通奸罪的 ,n. 掺假
4. susceptible   adj. 易受影响的; 易动感情的, 过敏的; 易受…感染的, 能经受的
5. image-specific 指定图像的
6. image-agnostic  图像不可知论  (universal)
7. obviate vt. 避免,消除(贫困、不方便等)
8. eliminate vt. 消除, 排除,忽略,淘汰〈口〉干掉
9. in lieu of  n. 代替, (以…)替代
10. aggregating 逐个增加
11. conj. 即使；虽然
12. in the vicinity of  在附近
13. precludes  vt. 妨碍；排除；阻止
14. spurious  adj. 假的；伪造的；欺骗的
15. adopts   vt. 收养 ,采用, 采纳, 采取, 正式接受, 通过
16. Thereupon 于是
17. derive  vt. & vi. 得到, 源于
18. encompasses  vt. 围绕;包围
19. curvature  n. 弯曲 弯曲部分 曲率,曲度
20. vice-versa  反之亦然
21. surrogate  n. 替代;代理
22. distinct <==> different
23. shed light on 阐明；使…清楚地显出  Through our formalization, we shed light on the most important factors for transferability.
24. Without loss of generality,
25. integrity and availability 完整性和可用性
26. In a nutshell   简而言之
27. posit  vt. 假定,设想,假设
28. corroborate  vt. 证实,支持(某种说法、信仰、理论等)
    n. 确证者;确证物
29. unmodified adj. 未更改的
30. input-agnostic 输入不可知
31. image-agnostic 图像不可知
32. adulterate vt. (尤指食物)掺假
    <废>奸污，诱奸
    adj. 掺杂的，掺假的；不纯的
    通奸的，犯通奸罪的
    n. 掺假

  

