---
layout: post
title: 【对抗样本(五)】On Physical Adversarial Patches for Object Detection
category: 文献阅读
tags: adversarial patches, adversarial attack
keywords: Object detection, adversarial attack
---

> 导语：这也是一篇针对目标检测的物理对抗性补丁的研究工作。
>
> 地址：https://arxiv.org/pdf/1906.11897.pdf
>
> github: 

### 摘要

在本文中，我们证明了一种可攻击目标检测器的物理对抗性补丁，也即著名的YOLOv3检测器。不同于之前在物理检测器的攻击，那些攻击需要用补丁附在目标物体上，使其被误分类或者躲避检测，我们展示了一种恰当设计的补丁来虚拟地抑制图像中所有的被检测的物体。也就是说，我们能将补丁附在图像中的任意位置，导致图像中所有的存在的物体都被检测器错过，甚至远离补丁它本身。这开启了攻击目标检测系统的物理攻击的新方向，不需要对场景中的物体进行修改。

### 1 Introduction

本文考虑了对抗性补丁的创造来攻击目标检测系统。广泛的，对抗性补丁攻击是指对机器学习系统的一类攻击，它向图像添加一些“补丁”或扰动，导致系统错误标记图像。不同于传统的对抗样本，他们是不可感知的，但是它能这样的一种方法在不改变人类直觉的情况下修改图像。过去的工作证明了这些攻击在分类场景下（Brown， Kurakin）的可行性（包括物理设置）和目标检测。然而，在目标检测设置下，这些攻击需要用户去修改被攻击目标它本身，如在目标上进行替代。

我们提出了一种替代性（更强的）对抗性补丁来攻击目标检测。具体的，我们构建了物理对抗性补丁，当附在图像中时，它将会抑制图像中所有其他的物体，甚至与补丁本身也会相差甚远。我们用于设计补丁的这种技术是现有技术相对直接的应用：使用EOT的PGD算法，具体地优化一个我们认为很适合目标检测系统的损失。

我们证明了我们在YOLOV3结构上的攻击，鲁棒地抑制对象在广泛位置上的检测。我们展示了我们反复的在COCO数据集上的性能，并且在webcam输入上事实了严重了物理攻击YOLOv3的性能。这些攻击可能对很多机器学习系统可能开启了一种新的威胁。例如，这表明它有可能抑制自动汽车视觉系统中所有的目标的检测（如行车线、其他车辆或路标），不需要我们修改这些目标，只需要在路边上防止一个设计的很好的对抗性补丁。

### 2 相关工作

机器学习系统的对抗性攻击研究得到了足够的关注，我们在此只关注与我们研究最相关的工作。

#### 2.1 分类的对抗性攻击

图像分类器的对抗性补丁攻击首先由brown在2017年提出。目标是生成局部、鲁棒和通用的对抗性扰动，通过mask而是不添加像素的方式。由Brown找到的补丁有能力欺骗多个ImageNet模型来预测烤面包机，无论其是否是视觉的，甚至可以经过打印出来作为一个贴纸。然而，由于分类器仅将每张图像分类成单个类别，在一定程度上攻击依赖于以下的事实，它能放置一个高置信度的“深度网络烤面包机”到图像中（尽管它看起来一点也不像烤面包机）并且覆盖图像中的其他类别。

#### 2.2 图像分类的对抗性补丁

由于分类设置的局限性，一些其他工作研究了目标检测设置中对抗性补丁。然而，对于该领域中具有物理对抗样本的样例很小，几乎所有的集中感兴趣目标的创建，来改变它的类别或者抑制检测。相反地，我们的方法专门针对不与场景中感兴趣对象重叠的对抗性补丁。

DPATCH的方法与我们的类似，利用创造的不与感兴趣的物体重叠的补丁。然而，DPATCH方法仅在数字图像上进行了测试，并且包含了包含了不适合真实实验的重要的流：在DPATCH中生产的补丁从未裁剪至图像像素允许的范围（如裁剪颜色到[0,1]范围），并且与实际的扰动图像不一致。进一步地，使用DPATCH的损失来获得合法的对抗性图像并不简单，我们有能力生产强大的攻击

### 2.3 YOLO

YOLO是“单阶段”目标检测器，在某些指标上有SOTA的性能，运行速度比其他模型快3倍。它将输入图像视作SXS的网格单元，每个单元格预测了B个边界框和他们置信度得分；并且每个框预测C个类别概率。特别地我们使用YOLOv3模型作为用于证明我们方法的目标检测系统，其他目标检测器同样也行。

### 3 方法论

#### 3.1 标记

让$h_\theta$表示了带参数$\theta$模型的假设函数；x表示了目标为y的输入$h__\theta$;并且J(h(x),y)表示了损失函数，由h0在输入x上映射的预测到目标y的一些实值数。

#### 3.2 攻击公式

我们提出了创建攻击目标检测对抗性补丁的方法论。注意这里的方法基于已有工作：带EOT的无目标PGD算法，但是这些攻击比前者更强。我们考虑使用如下的寻找对抗性补丁的数学公式

![](https://winterwindwang.github.io/assets/img/2021-06-18-eq1.png)

其中D是样本上的分布，T是补丁转换的分布，A是“补丁应用函数”，转换具有转换t的δ，并且通过掩蔽到图像中合适的像素，我们考虑了“通用的”对抗性扰动。

DPATCH方法通过预测到目标预测y的最小化损失，尝试一种目标函数，执行如下的公式：

![](https://winterwindwang.github.io/assets/img/2021-06-18-eq2.png)

这个更新工作在数字空间中工作地很好，我们的实验展示了使用这种方法找到的补丁在使用盒形约束下非常脆弱，需要很多次迭代更新，并且在相对较高的mAP的一致性平稳期。DPatch失败的详细原因如3.7节。

相反，我们采用更简单的方法，简单地从表面上取优化问题，并针对分别从 D 和 T 抽取的样本和变换直接最大化原始目标 y 的损失。这个本质上是标准的无目标PGD攻击，最初是由BIM引入，并使用EOT应用其中。更新并未将补丁δ推向任何指定的框盒或盒子。这与DPATCH在标签1中的更新，需要目标标签y的非目标和目标样例；这在在我们抑制检测目标中不是问题。与过去工作相同，我们考虑了L无穷正则化，更新过程如下：

![](https://winterwindwang.github.io/assets/img/2021-06-18-eq3.png)

样本$x \sim D$和转换$t \sim T$。

#### 3.3 实验设置

我们在预训练COCO2014数据集上（416x416像素）预训练的YOLO。YOLOv3的实现取得了大约55.4%的mAP-50（在0.5IoU指标上的mAP），使用的一种阈值为0.001的非极大值目标检测。由于mAP相当程度上受阈值的影响，在验证时，我们验证0.1阈值下的置信度，实时检测时使用的阈值为0.5。该实现在0.1的置信度上取得了50.3%的mAP值，0.5阈值下的40.9%。

我们将步骤设置为1000迭代。随后的实验使用了0.1的初始学习率和0.9的势能，这由启发性的选择。学习率使用了每5轮衰减了0.95，在这个点运行了验证步骤来求mAP的绘制点。由于损失是非凸的，我们采取了最佳的5随机来消除局部最优化的影响。补丁随机旋转了x，y，z的轴，随机缩放和转移，并且随机选择了补丁的明亮度（转移到HSV和缩放V）。

#### 3.4未裁减攻击

对于未裁减攻击，我们方法执行了公式2的更新，期望未裁剪。目的在于使用公式1攻击DPatch。这两种方法，转换t将补丁变换到120x120大小像素，并且附着在左上角。

![](https://winterwindwang.github.io/assets/img/2021-06-18-fig1.png)

图1展示了我们的方法在大约在仅5次后mAP能达到0，然而DPATCH要在50伦次后才能收敛到3左右。从我们的实验中，我低学习率或者快速衰减无助于帮助减少DPATCH的mAP值，这可能意味着损失函数本身的缺陷。

![](https://winterwindwang.github.io/assets/img/2021-06-18-tab1.png)

表1展示了不同置信度阈值的完整mAP和每个类别的最小和最大的mAP的结果。通过整个验证集上得到这些值，而不是单个步骤。我们的DPATCH结果与Liu等人报告的结果较为一致，他们在对YOLOv2和VOC 2007上的无目标攻击上得到了3.4mAP，由于实现和模型结构以及数据集的差异存在一定的差距。

为了验证我们补丁在边界框提前层级的攻击，对于随机图像，我们绘制了预非极大值抑制边界框置信度得分，如图2所示。

![](https://winterwindwang.github.io/assets/img/2021-06-18-fig2.png)

#### 3.5 裁剪攻击

对于裁剪攻击，我们的方法更新了公式2。我们比较了DPATCH，使用了公式1但是拆见到【0，1】。

图3展示了具有所有转换的裁剪补丁的损失和mAP的图表。特别地，我们在x，y轴随机旋转了【-5，5】角度，在z轴旋转了【-10，10】度。缩放至80*80到120\*120像素之间；使用【0.4，1.6】之间因子来调整明亮度。转换在后缩放过程，补丁可以出现在图像地任何位置，缩放是为了保证在旋转后补丁不会被切除。

![](https://winterwindwang.github.io/assets/img/2021-06-18-fig3.png)

DPatch方法快速收敛到攻击性微弱的补丁，我们取得了个位数的mAP值。正如在未裁剪的情况下，随机重启和超参数调优无助于帮助DPATCH提升性能。表2展示在整个验证集上打破AP的结果，这次在图像的随机位置施加了补丁。

![](https://winterwindwang.github.io/assets/img/2021-06-18-tab2.png)

我们的补丁取得了7.2的mAP，几乎与未裁剪的一样。裁剪后的DPATCH高于随即图像不多。我们的补丁同样捕获了语义上的有意义模式（斑马纹），这对于检测器而言是非常显著的。图5展示了我们补丁成功地吸引了大多数提前框的注意。

![](https://winterwindwang.github.io/assets/img/2021-06-18-fig4.png)

![](https://winterwindwang.github.io/assets/img/2021-06-18-fig5.png)

#### 3.6 物理攻击

图6展示了我们攻击使用标准webcam实时运行的YOLOv3补丁的打印版本。补丁由正常的打印纸打印出来，并在自然光下录制。期间补丁对于的位置变化不大，一般的补丁对目标的影响较小，如图7所示。当定位在侧面时，需要扩大补丁才能成功禁用远距离检测，而无法禁用足够自信的检测。补丁能够在移动过程中使检测失效，只要补丁它本身是稳定地，如图8所示。这显示了我们补丁可以在不同于训练数据集分布地情况下工作，并且可以用于不同光照条件、位置和方向上实现攻击。

![](https://winterwindwang.github.io/assets/img/2021-06-18-fig678.png)

#### 3.7 讨论

我们怀疑DPATCH效果不好是因为它聚焦在真实物体框附件生成补丁，它完全是在单个单元格内，这意味着损失可能由每个单元格的提前框“负责”。只要补丁被识别出来，可能在目标得分上遭受惩罚，但是不在边界框或者类别标签。因而损失可以减少，尽管模型行为并未改变太多。在实际中，补丁通常被没有抑制其他物体的高置信度检测到。在我们的方法中，每个单元格均与真实边界框重叠，来减少损失，当模型未能正确预测任何真实的边界框，损失将会增加。

### 4 结论

我们介绍了一种补丁攻击来使YOLOv3的mAP从55.4下降到个位数。我们展示了这种方法在无目标场景下优于现存的DPATCH方法，无目标攻击与目标攻击有同等重要的影响。最终，我们证明了通过打印我们的补丁，我们的攻击可以拓展到物理空间，并且通过webcam输入欺骗实时运行的YOLOv3，就我们所知，这是第一个不需要重叠补丁和目标物体就可以成功地抑制目标检测器的补丁攻击。

### 词汇

1. virtually 几乎