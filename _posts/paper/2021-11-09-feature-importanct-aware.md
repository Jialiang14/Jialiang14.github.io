---
layout: post
title: 【对抗样本（十六）】Feature Importance-aware Transferable Adversarial Attacks
category: 文献阅读
keywords: important-aware attack, transferable adversarial attacks
tgas: 特征重要性迁移攻击
---

关键词：VGG-16作为源模型的时候，可以获得最高的攻击成功率（这条在多篇论文中都有提及）。模型越大（越复杂），优化就越困难，也就越难以找到局部最优值（难已收敛）。

在原始批的干净图像中进行随机变换以得到一些列干净图像的梯度，然后使用这些梯度的均值来表征模型感兴趣的区域。**本质上是输入图像的变换上做操作**。

[code](https://github.com/hcguoO0/FIA)

---

## 摘要

对抗样本的迁移性是攻击未知模型的关键问题，迁移性使得对抗攻击更适用于实际场景，如黑盒攻击。现有的迁移攻击倾向于通过**不加区别地扭曲扰动**来构建对抗样本以降低原始模型地预测准确率，并**未意识到图像中目标特征的内在性质**。相反，作者提出特征重要性攻击（FIA），通过破坏重要目标意识特征，这主导了模型决策的一致性。具体地，作者通过介绍**积累梯度得到特征重要性**，这是原始模型特征图的梯度均值，这由在原始干净图像的随机变换计算得到。**梯度将与模型兴趣的区域高度相关**，这种**相关性提供了跨模型的不变性**。此外，**随机变换将保留目标对象的固有特征，并且抑制模型特定的信息**。最终，特征重要性知道搜索对抗样本以破坏关键特征，获得了强大的迁移性。大量的实验验证证明了FIA的有效性和优秀的性能，比如，比正常训练的模型的攻击成功率高了9.5%，与SOTA迁移攻击相比，对防御模型的性能提高了12.8%。

![image-20211123195149159](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123195149159.png)

## 引言

常见的黑盒攻击类型[33,14,2]通过查询估计梯度（概率向量和硬标签）来构建对抗样本，这种是查询攻击，大量的查询攻击在现实世界中是不切实际的，因为大量的查询是不被允许的。于此相反，典型的黑盒攻击，称为基于迁移攻击，依赖对抗样本的跨模型迁移性[21]，这更符合实际并且更加灵活。

然而，由传统方法构造的对抗样本通常由于对源模拟过拟合，从而展示出很弱的迁移性。有一些方法尝试通过在优化过程中引入额外操作来减弱这种过拟合，如随机变换[35]，转换操作[6]。最近，[36,23,7]通过直接攻击中间层来增强迁移性。**不同于扰动输出层，这些特征攻击最大化中间层失真从而得到更高的迁移性**。然而，通过**不加区分地扭曲特征**来构建对抗样本地现有方法并未意识到图像中目标物体地内在特征，因此很容易陷入局部最优。由于分类器倾向于提取任何可得到地特征来最大化分类准确率，甚至那些在图像中隐含地不可感知的噪声[15]，模型将学习额外的噪声特征以及目标的内在特征，但是**噪声特征与目标相关的特征被同等对待来支撑最终的决策，这种噪声特征将会是模型相关的**。因此，现有的对抗样本生成方法倾向于对源模型过拟合，并线阻碍了对抗样本的迁移性。

本文提出了一种特征重要性意识（FIA），通过扭曲对不同模型决策都具有主导作用的重要特征（不同模型上都），极大地提升了对抗样本的迁移性。为对抗特定模型的特征，作者引入**聚合梯度**，这能有效地抑制模型相关特征，同时能提供目标相关的重要性特征。如图1所示，与传统无区别攻击方法相比，FIA生成的攻击图像存在极大的散焦，即未能捕获目标的重要性特征。更具体地，**随机变换（随机像素dropping）** 被首先应用到原始图片上。因为**转换后地图像会保留空域结构和纹理，但是有不同的语义细节**，**它们的特征在对象感知特征上是一致的，但在非对象（即特定于模型的“嘈杂”）特征上会有所波动**。关于这些特征，对梯度进行平均，以统计方式抑制那些波动地模型特定特征。同时，目标相关和重要性特征被保留下来以知道更多迁移对抗样本地生成，因为特征重要性高度与感兴趣目标相关，并且在不同模型上保持一致性。

贡献：

+ 作者提出了一种FIA的方法来增强对抗样本的迁移性，该方法荣国破坏目标相关的关键特征，该关键特征主导不同模型的决策。
+ 我们分析了现有工作迁移性相对较低背后的逻辑，如对模型相关的噪声特征过拟合，作者通过引入聚合梯度来指导更多迁移性对抗样本
+ 在不同分类方模型的大量实验证明了由FIA方法生成的对抗样本相对于其他方法的优越性。

## 方法

作者提出的FIA方法的框架如下图所示

![image-20211123210428709](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123210428709.png)

随即变换的示意图如下图所示

![image-20211123210526736](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123210526736.png)

### 聚合梯度生成的特征重要性

 模型重要性与特征如何影响最终决策有关，直观策略是获得梯度，即

![image-20211123210739605](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123210739605.png)

其中l表示真实标签t对应的logit输出，fk(x)表示从第k层特征中得到的特征图。原始的公式2包含模型特定信息。正如图3所示，原始梯度图和原始特征图二者均有视觉噪声，即在目标区域的脉冲和大梯度，这可能是由于模型特定解决空间引起的。

为了解决模型特定信息，作者提出了**聚合梯度**，其从随机变换x中聚集梯度（如图4）。转换应该会损失图像细节，但是会保留空间结构和通用纹理。因为语义目标相关或重要特征/梯度对于这些变换具有一定的鲁棒性，但是模型特定的噪声就对这些操作很脆弱，这些鲁棒性/迁移性特征/梯度在聚合后变得明显，其他则会变得中性。在本文，作者采用了以概率pd的随机像素dropping（随机mask）。因此，聚合梯度可以表示成以下的形式

![image-20211123211600287](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123211600287.png)

Mpd是与输入x尺寸相同的二值矩阵，⚪表示了元素乘积。通过L2范数在相对应祥5上的归一化器C。集成数量N表示应用到输入x的随机mask的数量。聚合梯度会高亮鲁棒区域和关键目标区域特征，这能指导对抗样本向更具迁移性的方向。

### 攻击算法

利用上述重要性特征（聚合梯度），设计出如下的损失函数

![image-20211123212128277](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123212128277.png)

其中Δ表示重要性特征。直观上，重要性特征在Δ中将生成相对较高的密度，这显示对真实标签的正确反馈，Δ的符号提供了正确的方向。生成迁移性对抗样本的目标是减少正方向Δ中重要特征并且增加负方向Δ的相关性。因此，通过最小化公式4就能得到想要的目标。最终的目标函数为

![image-20211123212605817](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123212605817.png)

现有的很对基于梯度攻击的方法都能解决上述问题。如BIM，MIM[5]。由于MIM的强大性能，作者采用MIM。

### 相关攻击的缺点

进一步强调特征重要性相对于基于特征攻击（NRDM[24], FDA[7]）的优势在于。他们的损失函数分别是公式6和7

![image-20211123212842209](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123212842209.png)

使用l2范数来简单地衡量特征失真

以及不加区分地对所有特征进行扰动

![image-20211123212928847](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123212928847.png)

其中D是l2范数，Ck(h, w)表示跨通道激活均值。

从目标函数方面，NRDM简单地优化原始图像和对抗图像之间地特征失真地，没有任何约束。

对于FDA而言，尽管其引入了一种相似地利用特征激活地想法来指导优化，如支持正确决策地特征应该没抑制，但是这些不支持真实标签地应该被增强。然而，FDA使用跨通道均值作为可区分地指标，这无法有效地避免模型特点地信息。具体如算法1所示

![image-20211123213859852](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123213859852.png)



## 实验

#### 实验设置

数据：ImageNet-compatible，包含1000张图片，曾用于NIPS2017挑战赛

最大扰动量：16，迭代次数10， 迭代步长：α=ε/T=1.6。

攻击防御方法：pd=0.1，攻击正常方法pd=0.1

聚集梯度集成个数: N=30

对于特征层级的攻击，选择相同的层Mixed 5b for Inc-V3, Conv3 3 for Vgg-16, Conv 4a for InRes-V2, and the last layer of second block for Res-152.

#### 迁移性的比较

![image-20211123214955699](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123214955699.png)

攻击不同防御方法的攻击结果

![image-20211123215023347](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123215023347.png)

#### 聚集梯度中参数的效果

![image-20211123215109404](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123215109404.png)

不同层数的选择对结果的影响

![image-20211123215132172](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211123215132172.png)



## 结论

+ 靠近输入的网络层没有学习到显著性特征和真实类别的语义概念，靠近输出的层是包含模型相关的层。相反，中间层拥有很好的独立类别表示，并且不会与模型结构高度相关，因此中间层是用于提升攻击迁移性的最佳选择。
