---
layout: post
title: 【对抗样本（十）】Is Robustness the Cost of Accuracy A Comprehensive Study on the Robustness of 18 Deep Image Classification Models
category: 文献阅读
tags: explaining research, adversarial attack, the disclosed Pareto frontier
keywords: image classification models, adversarial attacks
---

---

1.  相同模型族具有较高的对抗迁移性
2. 模型结构对鲁棒性的影响大于模型大小
3. VGG网络结构的对抗样本的迁移性优于其他模型

---

## 摘要

为了解密模型鲁棒性和准确率之间的trade-off，本文使用多个鲁棒性指标彻底研究了18个基准ImageNet模型，包括失真，成功率，对抗样本在306对模型之间的迁移性。实验结果揭露了几个insight：

1. 线性缩放规则，经验地l2和l∞失真指标与分类错误对数呈现线性关系；
2. 模型结构对鲁棒性而言是比模型大小更关键的因素，闭式准确率-鲁棒性帕累托前沿可以用来验证ImageNet模型设计的好坏
3. 在l∞范数下，对于一个相似的网络结构（网络族），增强模型的深度对于提升鲁棒性的帮助很小
4. VGG模型族展现出很高的对抗迁移性。[代码][https://github.com/huanzhang12/Adversarial Survey]

## 1 引言

文献[13]、[14]理论分析了一些简单网络的鲁棒性，通过估计他们的全局和局部Lipschitz常数。[15]提出使用极值理论来估计最小对抗失真的下界，能够有效地应用到任何神经网络中。[16]提出了基于ReLU激活函数的线性近似的鲁棒下界。在本文，作者利用特定攻击和攻击认知方法评估了DNN模型的鲁棒性。

+ 具有低错误率的分类器更容易受到对抗攻击的影响。这可以验证设计神经网络的鲁棒性的好坏。
+ 相同网络族，共享相似的鲁棒性属性。相比于模型大小，模型结果对鲁棒性的影响更大。
+ 由VGG模型族生成的对抗样本可以较好的迁移到其他17个模型上 。其他大部分模型都仅能泛化到其他少数几个模型。
+ comprehensive study

### 2.1 深度神经网络结构

+ AlexNet
+ VGG Net: vgg16,vgg19
+ Inception Net: v1,v2,v3,v4 inception-resnet
+ Resnet: 3种
+ DenseNet: 3种
+ MoibleNets: 3种
+ NASNets： 

### 2.2 攻击方法

+ FGSM
+ I-FGSM
+ C&W
+ EAD-L1
+ CLEVER

### 2.3 数据集

ImageNet。从ImageNet验证集中随机选择1000张图片来为每个模型生成对抗样本。对于每个模型，进行了目标攻击和最不同无目标攻击。

### 2.4 评估指标

+ 攻击成功率：

  + 无目标攻击：对抗样本的预测标签与真实标签不一样的比重（最不能类别）
  + 目标攻击：对抗样本被分类为指定类别的比重

  作者认为更高的成功率表明模型更容易受到攻击，反之说明模型的鲁棒性更好。

思考：两个问题：第一个是无目标攻击不能称为是攻击成功率，而应该定义成fooling rate；第二个是不同攻击算法的性能是存在差异的。（但是如果在相同的对比条件下，应该可以说明问题？）

+ 失真：使用来l2和l∞衡量对抗样本图像与干净图像的差异。

  + l2范数：两张图象之间的欧氏距离（由于不同图片的尺寸不一样，为公平比较在图像像素的总数计算l2范数）
  + l∞：在两张图象之间任意像素的最大绝对值差异

  更大的失真通常表明更鲁棒的模型。（需要更大的扰动来使模型预测出错，但是者也受到攻击算法的影响。但是针对不同模型，使用同一种攻击算法确实能说明一些问题）。作者还针对不同模型，搜索了不同攻击方法的最优参数。

+ CLEVER score：对于每张图像，计算其与随机目标类别和最不可能类别对抗样本的l2CLEVER得分。报告的数字是所有测试样本的均值。该值越高，模型越鲁棒。

+ 迁移性（参考31的设置）：

  + 无目标攻击（error rate）：对源模型生成的对抗样本也能使目标模型分类错误。。更高的值意味着更好的无目标迁移性。
  + 目标攻击（match rating）：源模型和目标模型都将对抗样本分类成指定的类别。更高的值意味着更好的目标攻击迁移性。

  

## 3 实验

18个模型，ImageNet作为基准数据集

### 3.1 对抗攻击的评估

未来验证每个模型的鲁棒性，原始的误分类图像被排除。

### 3.3 不同模型大小和结构的鲁棒性

作者发现对模型鲁棒性的影响因素中模型结构是比模型大小更重要。尽管模型的大小和深度不同，但每个网络家族展现出相似层级的鲁棒性。AlexNet模型的鲁棒性最好（60million参数），而mobile模型最差（1.5million参数）

对于DenseNet， ResNet和Inception而言，在l∞失真指标下，更深的网络架构带来的鲁棒性提升很小。

### 3.4 对抗样本的迁移性

使用了不同的指标：无目标迁移性攻击，top-5 matching rate来验证目标迁移攻击。（**注意：定义？指定的目标只有一个，5个目标怎么评估？**）

由于不是所有模型的输入都是一样的，因此对图片进行resize。然而[50]指出，简单的resize操作会极大地降低迁移攻击成功率。未来缓解这个问题，作者采用了以下策略：

+ 大尺寸对抗样本在小尺寸模型输入上：从图像中心进行裁剪
+ 反之：在对抗样本的四周加white boarder白色边界。

结论：

1. 在无目标迁移攻击设置下，FGSM和I-FGSM具有较好的迁移攻击成功率。

![image-20211102193740826](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211102193740826.png)

2. 在无目标迁移攻击设置中，FGSM，大的ε值生成较好的迁移性样本；然而对于IFGSM,更少次的迭代生成迁移性更好的对抗样本。对于无目标EAD-L1，高的k值导致更好的EAD-L1，但是远小于I-FGSM方法。
3. 对抗样本的迁移性有时候是不对称
4. VGG网络族的迁移性优于其他模型
5. 最近大部分网络有一些独特的特征，将对抗样本的迁移性限制到相同的族内。相同结构不同深度的网络几乎具有100%的网络迁移性，但是他们对其他未知模型的迁移性却很差。

实验结果看原文。