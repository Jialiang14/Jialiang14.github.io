---
layout: post
title: 分割网络攻击中的对抗样本防御方法
category: 文献阅读
keywords: adversarial defense, segementation network
tags: 对抗样本防御, 分割网络
---

# 【ICCV2021】Dynamic Divide-and-Conquer Adversarial Training for Robust Semantic Segmentation
一句话概述：鲁棒语义分割的动态分而治之对抗训练

---

## 摘要

在**分割任务**中的对抗训练的效果**刚刚开始**。作者首次舱室探索语义分割任务中的防御技术，通过构建一个通用的对抗训练过程，可以在对抗样本和干净样本上表现得不错。作者提出了一种动态分而治之得对抗训练策略（DDC-AT）来增强防御效果，通过在训练时在目标模型设置额外的分支，处理具有不同属性的像素，以进行对抗性扰动。作者**提出的动态机制自动的将相似分割成多分支**。注意，这些所有的额外的分支在推理阶段都可以被丢弃，因此不会引入额外的参数和计算代价。在VOV2012和Cityspace数据集上，不同分割模型上的大量实验证明，DDC-AT可以获得较好的结果。

![image-20211220002938028](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220002938028.png)

## 引言

对于语义分割任务而言，每个像素都有一个类别输出。因此**图像中每个像素对对抗样本的属性都可能不一样**。基于这个灵感，作者设计了一种动态分而治之的对抗训练策略。作者提出在训练阶段，**目标模型训练使用多分支**，每个处理的像素都具有一些属性。在训练期间，主分支被采取用于处理从对抗样本的像素与从干净样本（看起来不像被扰动）的像素。一个”辅助分支“被用于处理来自干净样本（对扰动不敏感）的像素。

此外，**这种分而治之的设置是动态的**。在训练期间，靠近决策边界的干净样本的像素被初始化设置成”辅助分支“。**在”辅助分支“中的像素对扰动更加敏感**。这种动态的过程**由训练”mask 分支“实现**。使用这种方法，作者的方法减少了干净样本上性能的下降。

标准的对抗训练方法如下图所示

![image-20211220005315923](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220005315923.png)



## 方法

作者提出的DDC-AT框架如下图所示

![image-20211220004308609](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220004308609.png)

**分割像素**：图中所示，在训练期间，在输入空间中的干净像素可以被分割成两种类型，根据他们的”决策边界属性“。

1. 不具备决策属性的**像素A**：**干净像素和他们的对抗样本像素在相同的分类空间**（安全训练区域）。**这二者的属性在输出空间是类似的**。他们通常**远离决策边界**。他们的分布与使用对抗训练的分支相同。
2. 具有”决策属性“的**像素B**：干净像素和对抗像素在不同的分类空间。这种干净的像素更接近决策边界（扰动敏感区域）。他们**具有”边界属性“，因为他们很容易被扰动从而越过边界**。在相同的分支直接将他们与对抗像素对齐是有难度的。作者提出首先使用不同的分支来分布训练。一旦干净和对抗像素在相同空间，就在相同的分支对他们进行对齐。

**征服像素**：

基于上述分割设置，作者提出的框架如图2所示，包括3个分支：主分支fm，附属分支fa，以及掩膜分支fm。前二者可以用于征服像素，如为每个像素预测标签，然后将他们指定到相应的网络。主分支征服像素A，附属分支征服像素B。通过这种方式，图像中的干净像素就可以通过不同的分支进行处理。注意前二者共享backbone。他们在特征层级互相帮助。fm用于推理阶段

**合并像素**：

正如图2b所示，分离的像素在被征服后重新合并。因此一张图像中的所有像素都被分成了fn和fa，分配给他们二者之间的像素没有重叠。因此，他们可以合并到最终的预测来计算损失。这也表明，在训练阶段，输出空间用于决策的应该由fn和fa组合得到。

### 实现细节

DDC-AT分布所有对抗像素到fn，对干净图像则使用动态分离。上述分离使用fm实现。

（a）预测像素B

首先，fm在输入图像中预测像素B，如图2b所示。对于输入x，从fn，fa，fm的输出分别是on，oa，om，其中$o_m \in R^{H\times W \times 2}$。om的标签图为$p \in R^{H\times W}$，他是二值矩阵，用于决定分割。p(i,h)=1意味着像素x(i,j)属于B，然后输出fa。否则输入fn。该操作生成x的组合输出为o=oa * p + on*( 1-p)。\*是哈曼达积。

（b）ground truth

理想分割策略是基于组合输出。该策略有掩膜标签，记为M，其中$M \in R^{H\times W}$，M(i,j)=1意味着在(i,j)处的像素属于B，并被分到fa。

(c)训练

根据DDC-AT中理想的分割策略得到Madv,Mclean，将他们当作gt训练fm。重复整个过程使fm学会如何取得自动对像素的理想分割效果。整个过程如算法2所示。

![image-20211220011419911](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220011419911.png)

### 总的损失函数

对于训练数据x，它的标签图由mask分支得到，为p，令q=1-p，得到损失函数

![image-20211220010216979](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220010216979.png)

将mask 标签M转换成独热编码的形式，fm的损失变成

![image-20211220010351957](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220010351957.png)

总的损失为

![image-20211220010403424](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220010403424.png)

总的训练过程如算法3所示

![image-20211220010435514](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220010435514.png)

### 分而治之的优越性

与SAT相比，DDC-AT的优越性。

+ 对于分割而言，通常**干净样本中所有的像素都在加了扰动后会发生变化（干净样本中一些像素的预测值不会因为加了扰动而发生变化）**。一些像素有边界属性，而另一些没有。将这两类像素分别进行处理就是作者提出的策略。
+ 对于主分支fn中干净样本的训练要比混合A和B更难。**DDC-AT中引入的辅助fa可以有效地将B转换成A**。因此，主分支fn用于推理可以更好的处理干净像素，并提交acc。
+ 为在对抗像素上获得不错的结果，SAT在主分支fn上使用A和B一起训练对抗像素。显而易见，同时使用A和B训练会导致训练比仅使用A训练更难。因此DDC-AT可以在对抗像素上获得更好的效果。

## 实验

分割网络：PSPNet、DeepLabv3

### VOC2012上的实验结果

+ 可视化对比结果

![image-20211220012406490](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220012406490.png)

+ 白盒攻击：表1展示了在VOC上不同防御方法的结果

![image-20211220012450305](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220012450305.png)

表 1 基本表明，**在攻击迭代次数大的对抗样本上的结果代表了每种方法在对抗性扰动上的下界，因为相应的性能随着 n 的增加而降低**，并在 n 大时收敛。

+ 黑盒攻击：

![image-20211220012810220](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220012810220.png)

表2展示了，对于BIM攻击而言，干净模型上的性能也会随着攻击迭代次数的增加而降低。

#### 消融实验

详见论文

![image-20211220013000367](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20211220013000367.png)