---
layout: post
title: NeuroIPS 2021有关对抗样本的论文集
category: 文献阅读
keyworks: adversarial examples, adversarial attack
tags: 对抗样本攻击，对抗样本的理论解释
---

# A single gradient step finds adversarial examples on random two-layers neural networks（单步梯度就能在随意的两层神经网络中找到对抗样本）


## 摘要



## 相关结论

1. 作者证明了单步梯度下降就足以找到对抗样本
2. 作者发现不是所有的网络都可以使用单步攻击找到对抗样本

​	We note that not all networks are susceptible to one-step gradient attacks to find adversarial examples.

+ FGSM作者发现对抗训练可以用于抵抗一些单步梯度攻击
+ PGD作者发现能够抵抗单步攻击的对抗训练仍然容易受到多步的梯度攻击，并且经验性的证明了在多步梯度攻击的对抗样本上进行对抗训练的鲁棒性更好。

为了从理论上解释上述现象，也有一些工作。

3. Daniely和Schacham发现多步梯度攻击为ReLU随机网络找到的对抗样本，只要满足神经元的数量远远小于其维度。作者在本文证明了这个观点。
4. 作者还指出，存在一种“通用”对抗扰动，可以泛化到不同输入和网络模型。对于ReLU激活函数，作者发现可以**沿着某个独立于输入x的方向**而不是梯度方向，**证明通用对抗样本的存在**。
5. 作者探究了在不同网络层的设置下，针对不同输入维度，构成对抗样本所需的神经元也不同。

# Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks

StdCNN：标注卷积神经网络

group-equivariant NN（GCNNs）：群等变模型

## 摘要

作者解决了神经网络模型中平均情况空间鲁棒性和最坏情况L∞对抗抗鲁棒性之间不可避免的权衡，并在理论和经验上展示了结果。一方面，作者通过等变模型与大规模训练增强获得更好的空域鲁棒性，但是对抗鲁棒性变差了。另一方方面，通过对抗训练以抵抗大的像素层级扰动来获得更好的对抗鲁棒性，但是空域鲁棒性变差了。然后，作者提出了一种基于学习课程的方法来消除这个问题，并且达到了帕雷特前沿。

与现有工作相比，有两个重要的进步：

1. 对更多的攻击鲁棒，以及在鲁棒性和准确率上取得了平衡
2. 与对L∞的对抗扰动的鲁棒性相比，对平移和旋转的鲁棒性展示出了一种非常不同的损失景观

总而言之，作者的方法可以看作是一种在对抗鲁棒性和泛化性准确率本身之间的trade-off的提升。

作者认为现有方法无法同时在对抗鲁棒性和随机空域鲁棒性上接近帕雷特前沿。无论是先进行对抗训练然后进行大规模数据增强实验来增强空域鲁棒性，都会使得另一方的效果变差。作者表明使用curriculum learning based 策略可以有效的提升该性能。作者通过将对抗性扰动应用于具有逐渐增加难度级别的随机变换输入来训练模型，从而在已知数据集和模型中始终更接近帕累托最优边界的解决方案

## 相关工作/结论

1. 近期一些工作表明随机空域变换，如随机转换和随机旋转也会极大地降低神经网络地准确率.[12]
2. 标注的卷积神经网络是平移等变的，近期的一些工作研究了其他变换的等边NN模型，如旋转，反转和缩放。
3. 最近GCNN被设计对一组特殊变换鲁棒的模型，它们需要训练数据增强以获得空域上对随机和平均情况变换的鲁棒性。
4. 二环内管理模型的在ε大小的L∞下的对抗鲁棒性是NP难问题[24,37]。
5. PGD被认为是当下最强的攻击。[2].
6. 与鲁棒性认证下届的研究相比，作者分别研究了在空域和对抗鲁棒性上的上界。

# Adversarial Examples in Multi-Layer Random ReLU Networks

## 摘要

作者考虑具有独立高斯参数的ReLU网络中的对抗性示例现象。对于深度恒定且宽度范围较大的网络（例如，如果每层的宽度是任何其他层的多项式就足够了），输入向量的小扰动会导致输出的巨大变化。作者证明了对抗样本在更宽更窄以及两层网络中也存在，因为它们计算的函数局部与随机线性函数非常相似。瓶颈层扮演了关键的角色：网络中某个点的最小宽度决定了到该点计算的映射的比例和灵敏度。主要结果是对于具有恒定深度的网络，但我们也表明，对于这种结果，对深度的一些约束是必要的，因为存在适当的深度网络，它们以恒定的概率计算出接近常量的函数。

## 相关结论

1. 作者证明了对抗样本也存在于使用了随机权重的深度ReLU的各种网络结构中，那些具有常数深度于多项式相关的宽度。

# Adversarial Attack Generation Empowered by Min-Max Optimization
作者的对抗攻击方法可以找到最好的对抗样本，从而使得在这种样本上进行的对抗训练更加有效。

作者的贡献如下

+ 在最小最大化优化的帮助下，作者提出了一个**统一可替换**的单步投影梯度下降上升攻击方法（APGDA），可以很容易的生成模型集成攻击，通用对抗攻击，在数据转换上的鲁棒攻击。
+ 作者证明了APGDA可以有O(1/T)的收敛率，T是迭代次数。
+ 作者设计了最小化最大化攻击方法，作者设计了一种自适应权重选择方法，分别集成不同模型/数据集/图像变换方法

##  相关结论

1. 对抗训练在防御无穷范数输入扰动时，取得了sota的结果
2. MSD是当下防御多种Lp范数的SOTA防御方法。

# 【周五讲述】Distilling Robust and Non-Robust Features in Adversarial Examples by Information Bottleneck

一句话概述：作者提出利用信息瓶颈的方法划分出鲁棒和非鲁棒特征。

---

## 摘要

最近的工作表示现有的鲁棒和非鲁棒性特征是引起对抗样本的主要原因，并且研究了特征空间之间的中间特征。作者在本文中提出了**一种信息瓶颈方法将特征表示蒸馏成了鲁棒和非鲁棒特征**。具体而言，作者将不变噪声添加到每个特征单元并且验证特征表示的信息流中以区分特征是否鲁棒性，基于强度不变的噪声。实验证明，蒸馏的特征与对抗性预测高度相关，并且这些特征具有人类相关语义信息。最后，作者提出了一种强化与模型预测相关的非鲁棒特征梯度的方法的对抗攻击方法，并且验证其在破坏模型鲁棒性的效果。

# Shift Invariance Can Reduce Adversarial Robustness

## 摘要

移位不变性是 CNN 的一个关键属性，可提高分类性能。然而，我们表明，对循环偏移的不变性也会导致对对抗性攻击的更敏感。我们首先表征使用移位不变线性分类器时类之间的边距。我们表明，裕量只能取决于信号的直流分量。然后，使用关于无限宽网络的结果，我们表明，在某些简单的情况下，完全连接和移位不变的神经网络会产生线性决策边界。利用这一点，我们证明了神经网络中的移位不变性为两个类的简单情况生成了对抗性示例，每个类都由一个图像组成，该图像在灰色背景上有一个黑色或白色的点。这不仅仅是一种好奇心。我们从经验上表明，对于真实的数据集和现实的架构，移位不变性会降低对抗鲁棒性。最后，我们使用合成数据来描述初始实验，以探测这种连接的来源。



作者将padding的方式作为网络的位移不变性。

网络的padding越大，模型的位移不变性越强。

## 相关结论

1. FC网络比位移不变的CNN的网络更加鲁棒，特别是在更强的攻击强度下。

2. 若减少CNN的位移不变性，就能提高网络在这些数据集上的鲁棒性。

3. 在SVHN数据集上，FC网络比ResNet结构更加鲁棒，这表明这个现象可以拓展到真实卷积网络中。

4.  VGG和ResNet在某种程度上是位移不变的，而AlexNet和FCN以及基于transformer的结构要差得多，这表明前者不如后者鲁棒。

5. 提高训练数据的维度会降低模型的鲁棒性。

6. 对抗性例子的一个常见解释在于维度的诅咒；

   1. KHM【Khoury&Hadfield】从理论和经验上认为，对抗样本出现的原因是当数据位于高纬度空间的低维度流形。

7. 其他一些研究认为对抗样本的出现是数据的属性。

   1. Wang等人认为对抗样本可以解释成模型对图像数据的高频信息依赖。
   2. Tsipras认为由于特征偏差，获得高的准确率必须以牺牲鲁棒性。
   3. 随后的工作Schmidt等人展示对于对抗性鲁棒分类器以实现良好的泛化，样本复杂性要求远高于普通分类器。
   4. 最近的研究，Chen等人展示在某些情况下，更多的数据实际上破坏了对抗性的鲁棒性，也为这一系列研究提供了更完整的画面。

8. 除了数据之外，一些论文还在模型中寻找解释。

   1. Nakkiran等人推测对抗鲁棒性的原因很难获得，当前的分类器仍然不够复杂。
   2. Shah等人表明在许多情况下，网络学习简单的决策边界，具有较小的利润，而不是更复杂的具有大利润的决策边界，这会导致对抗性漏洞。
   3. Daniely表明具有随机权重ReLU网络，大部分样本x承认距离对抗扰动，其中d是输入维度。
   4. Shamir等人表明ReLU网络，对抗样本作为R的几何序列出现，并且表明他们可以在L0距离内找到目标对抗样本内，网络被设计用于区分m个类别。
   5. Galloway等人提供了经验证明，使用BN可以减少对抗鲁棒性。
   6. Madry和Wu等人讨论了鲁棒性和网络宽度的关系
   7. Kamath等人检查了旋转不变性和鲁棒性之间的相互关系。他们的实验表明通过使用数据增强来减少更多的旋转不变性和组等变CNN，这些模型的对抗鲁棒性会减少。

9. 具有无限宽度的神经网络（具有无限数量通道的卷积网络）行为就像具有一系列核的回归。

10. 卷积神经网络满足以下的假设就称其具有位移不变性

    + 包含N个全连接或局部pooling层以及一个全局pooling层，最后跟上一个全连接层
    + 在卷积和池化层中使用Circular padding

    这样的具有步长为p1，p2,...,pn的卷积和池化层的CNN网络对于P像素的位移具有不变性，其中P是任意p1,...,pn乘积的整数倍。

11. 针对padding的模式，现在有一些工作在此问题上已经进行了讨论

    1. Kayhan等人讨论了padding的模式
    2. Zhang等人和Kayhan等人认为应用在真实问题上的结构通常不具有位移不变性。
    3. Zhang等人展示了使用zero padding的真实结构在训练以后仍然保持近似不变性。
    4. 其他常见的缺乏位移不变性的原因是使用全连接层作为全局池化的替代，这在早期的网络结构中非常常见，如LeNet和AlexNet。然而，最近的研究通常使用全局池化(ResNet等)。

12. ResNet具有更高的干净准确率，但是在对抗样本上的准确率更差，特别是当ε很大的时候。这表明ResNet的近似位移不变性的鲁棒性更差。

13. AlexNet在移位不变性和鲁棒性方面确实是一个异常值。

14. Galloway等人认为BN是照成对抗样本的一个原因。但是即使是没有BN层的VGG网络，AlexNet具有更少的不变性以及更好的鲁棒性，这表明位移不变性导致缺乏鲁棒性。

15. 相比于CNN网络模型，VIT具有更好的对抗鲁棒性。作者将其原因归于VIT没有使用位移不变性。

16. 位移不变性越少的分类器，如AlexNet和Sparse-MLP具有更好的鲁棒性。

17. 同样对于大 p，不同 n 值的鲁棒性相似，这表明线性边距比数据的维数更好地预测鲁棒性。

# Fair Classification with Adversarial Perturbations

关键：**Fair classification**

## 摘要

我们在存在无所不知的对手的情况下研究公平的分类，给定一个，允许选择训练样本的任意分数并任意扰动其受保护的属性。动机来自由于误报，恶意行为者或插补错误而导致受保护属性不正确的设置;而先前对错误做出随机或独立假设的方法可能无法满足他们在这种对抗性环境中的保证。 我们的主要贡献是一个优化框架，可以在这种对抗性设置中学习公平的分类器，并附带可证明的准确性和公平性保证。我们的框架适用于多个非二进制受保护属性，专为大型线性分数公平性指标而设计，并且还可以处理受保护属性以外的扰动。我们证明了我们的框架对自然假设类的保证近乎紧密：**没有算法可以具有明显更好的准确性，任何具有更好公平性的算法都必须具有较低的准确性**。根据经验，我们评估了由我们的框架生成的分类器，用于对一系列对手的真实世界和合成数据集进行统计。

## 相关结论

1. 在高层次上，如果分类器 f 在 Z 定义的不同受保护组上的给定度量具有相似的“性能”，则称分类器 f 对于受保护属性 Z 是“公平的”。给定公平度量和 假设类 F，公平分类框架考虑寻找分类器 f 的问题可以认为是在限制的给定的公平性指标上的公平性最大化精确度。为指定公平性约束，这些方法需要已知训练数据的受保护的属性。
2. 然而，受保护的属性因为各种原因可能导致错误；比如
   1. 在数据收集或数据净化过程中[20,52]
   2. 或战略性误报[46]
   3. 受保护的属性可能因为种族或道德的因素而导致整体的丢失[20]
   4. 当数据是从网上爬取的数据集。[46]
   5. 或者由各种污染方法污染[29]
   6. 样本 间错误的相关性[49]
3. 为解决上述问题，很多工作提出旨在为各种在受保护属性的犯错的模型开发一种公平的分类算法。
4. 作者则从最**糟糕的对抗扰动（worst-case）**的角度研究了公平性分类。

# ☆Clustering Effect of (Linearized) Adversarial Robust Models

## 摘要

随着对抗性示例的研究，对抗鲁棒性也受到了越来越多的关注。到目前为止，现有的研究表明，鲁棒模型不仅可以获得针对各种对抗性攻击的鲁棒性，还可以提高某些下游任务的性能。然而，对抗稳健性的潜在机制仍然不清楚。在本文中，我们**从线性分量的角度解释对抗鲁棒性，并发现综合鲁棒模型存在一些统计属性**。具体而言，**鲁棒模型在移除或替换所有非线性组件（例如，批量归一化、最大池化或激活层）时，对其线性化子网络显示出明显的分层聚类效应**。基于这些观察，我们提出了对对抗鲁棒性的新理解，并将其应用于更多任务，包括领域适应和鲁棒性提升。实验评价证明了所提出的聚类策略的合理性和优越性。

作者方法的具体流程如下：

1. 首先将数据的子类别/细粒度类别（如猫狗）定义定义成一个超类/粗类别（如动物）
2. 然后作者在线性的鲁棒子网络和非鲁棒子网络上执行反向传播（对抗/标准训练）来提取相关的隐私线性表示，然后得到$D_{input}\times D_{output}$线性矩阵W，这是从其输入到预测结果上提取的。Dinput表示输入维度，定义成宽高通道的积。Doutput表示一个输出向量，即类别的数量。然后作者通过矩阵C研究了权重W中的相关性C，C的尺寸是$D_{output}\times D_{output}$
3. 然后，作者发现在相关性矩阵C中，鲁棒性模型倾向于展示出层级聚类效应，这与类别层级呈现惊人的相似。

## 相关结论

1. 作者通过提取隐式的线性矩阵表示对提出了一种新颖的线性模型解释。并且发现在鲁棒模型中存在一种聚类效应，这与类别层级有很好的对齐。作者艘次提出了一种对鲁棒模型的深刻见解，其在提取更多的表示特征和语义信息上展现出很好的能力。大量的实验表示，强化层级聚类效果不仅可以提升模型鲁棒性，同时也有助于下游领域自适应任务。

2. 现在已经有一些工作探究DNN模型的一些特定组件的对抗性了，如

   1. BN[12]
   2. 跳跃连接[34]
   3. 激活层[14,4]

   这些研究给出了一些启发性的解释

3. 作者认为尽管DNN中有各种不同的组件，但是这些组件都可以统一分成线性和非线性的组件。

   1. 非线性分量往往是实例上的。如对抗样本和干净样本在激活值上呈现出不一样的图案[4]
   2. 对于线性组件，一旦优化完成后，在验证阶段当模型被激活时，它们是独立于输入共享和固定的。

4. 一些人将对抗性归咎于扰动从输入到输出的积累，形成意外的隐写术[13]；

5. 还有一些人认为线性反向传播增强了对抗迁移性[34,14]。

6.  有一些工作研究通过研究网络层权重的属性，如范数，方差和正交性来研究对抗样本的线性性。

   1. LP范数正则化将样本退离决策边界，这是对抗鲁棒性的副作用。[37,18]
   2. 谱范数常用于对抗防御，其定义为$\delta_i=\frac{||w_ix||)_2}{||x||_2}$,并且对DNN网络进行拉普拉斯常数的约束。[7,26]
   3. 权重的缩放位移问题也同样被讨论[22]，权重的缩放不会改变网络的输入和输出函数，这可能会影响规范模型的能力。因此，权重缩放不变性规范化被提出用于提升对抗鲁棒性。
   4. 通过引入不相关特征，正交性有助于提升泛化性和对抗鲁棒性。

   作者认为，尽管做出了这些解释，但是他们**大都在原始的非线性模型上分析线性性**，直接阻碍对线性的更深入理解。

7. 子类在相同超类的中心靠近他们各自的特征空间。特征距离效应与类别层级呈现出很好的对齐效果。
