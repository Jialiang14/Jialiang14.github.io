---
layout: post
title: 机器学习/深度学习中常见的衡量指标
category: 深度学习技术
tags: evolution mertics
keywords: AUC, ACC, ROC, PR
---

---

#### 前言 本文主要介绍了机器学习/深度学习中常用模型指标

​	 		---- (参考博客)

---

+ 混淆矩阵-Confusion-Matrix

#### 1. 混淆矩阵

在机器学习领域和统计分类问题中，混淆矩阵是可视化工具，特别用于监督学习，在无监督学习一般叫作匹配矩阵。矩阵的每一列代表一个类实例预测，而每一行表示一个实际的类的实例。如下表所示是一个三分类系统的预测结果（主对角线的值表示系统预测正确，对角线以外的值表示系统预测错误）

|                |        | **实际的类别** |        |        |
| -------------- | ------ | -------------- | ------ | ------ |
|                |        | **猫**         | **狗** | 猪     |
| **预测的类别** | **猫** | **15**         | 12     | 8      |
|                | **狗** | 11             | **13** | 10     |
|                | 猪     | 9              | 12     | **16** |

在预测分析中，混淆矩阵通常是具有两行两列的表，如下。

|                |                | **实际的类别**                            |                                       |
| -------------- | -------------- | ----------------------------------------- | ------------------------------------- |
|                |                | Positive（正样本/阳性）                   | Negative（负样本/阴性）               |
| **预测的类别** | Positive（真） | **True** <br />实际为正类<br />预测为正类 | False<br />实际为负类<br />预测为正类 |
|                | Negative（假） | False<br />实际为正类<br />预测为负类     | True<br />实际为负类<br />预测为负类  |

很多评价指标都源自于上表的简化版（下表）

|                |          | **实际的类别** |          |
| -------------- | -------- | -------------- | -------- |
|                |          | Positive       | Negative |
| **预测的类别** | Positive | TP             | FP       |
|                | Negative | FN             | TN       |

+ T**P**： 实际类别为正类，系统预测也为**正**类（分类正确）
+ T**N**：实际类别为负类，系统预测也为**负**类（分类正确）
+ F**P**：实际类别为负类，系统预测也为**正**类（分类错误）
+ F**N**： 实际类别为正类，系统预测也为**负**类（分类错误）

一般而言，系统的TP和TN越高，FP和FN越低越好，这表示系统可以准确地区分正负样本。

#### 2. 准确率（Accuracy）

准确率是表征混淆矩阵中正对角线上被正确分类的样本之和占总样本的比率。

|                |          | **实际的类别** |          |
| -------------- | -------- | -------------- | -------- |
|                |          | Positive       | Negative |
| **预测的类别** | Positive | **TP**         | FP       |
|                | Negative | FN             | **TN**   |

​			                	$Accuracy = \frac{TP+TN}{TP+FP+TN+FN}$， 也即$Accuracy = \frac{TP+TN}{样本总数}$

#### 3. 精确率（查准率，Precision）

精确率定义为，从模型预测的角度上看，`在所有预测为正样本中，标签与真实样本同为正样本的比例`，表示模型对于预测正确的**置信度**。（在下表中，TP占该行的比例，横着看）

|                |          | **实际的类别** |          |
| -------------- | -------- | -------------- | -------- |
|                |          | Positive       | Negative |
| **预测的类别** | Positive | **TP**         | **FP**   |
|                | Negative | FN             | TN       |

​									        		$Prcision = \frac{TP}{TP+FP}$

#### 4. 召回率（查全率，Recall）

召回率定义为，`从真实标签的角度上看，在所有的正样本中，被模型正确地预测为正样本所占的比例`

（在下表中，TP占该列的比例，竖着看）

|                |          | **实际的类别** |          |
| -------------- | -------- | -------------- | -------- |
|                |          | Positive       | Negative |
| **预测的类别** | Positive | **TP**         | FP       |
|                | Negative | **FN**         | TN       |

  																$Recall= \frac{TP}{TP+FN}$

#### 5. F1得分（调和精确率与召回率）

观察`Precision`与`Recall`的公式，可以看出这两个公式的分子都相同（`同为TP`），其计算都是围绕着正样本的预测性能来计算的，同时`Precision`与`Recall`之间存在不可调和的矛盾（由于分类阈值的不同，`FP`和`FN`的值不同），如下表所示：

| 样本编号 | 真实类别 | 模型预测值 | 阈值为0 | 阈值为0.9 |
| -------- | -------- | ---------- | ------- | --------- |
| 1        | 1        | 0.9        | 1       | 1         |
| 2        | 1        | 0.8        | 1       | 0         |
| 3        | 1        | 0.7        | 1       | 0         |
| 4        | 1        | 0.6        | 1       | 0         |
| 5        | 1        | 0.5        | 1       | 0         |
| 6        | 1        | 0.4        | 1       | 0         |
| 7        | 0        | 0.3        | 1       | 0         |
| 8        | 0        | 0.2        | 1       | 0         |
| 9        | 0        | 0.1        | 1       | 0         |
| 10       | 0        | 0.05       | 1       | 0         |

**当阈值为0时，预测结果如下表所示**

| 阈值为0        |          | **实际的类别** |          |
| -------------- | -------- | -------------- | -------- |
|                |          | Positive       | Negative |
| **预测的类别** | Positive | 6              | 4        |
|                | Negative | 0              | 0        |

Precision = 6 / (6 + 10) = 0.6

Recall = 6 / (6 + 0) = 1

**当阈值为0.9时，预测结果如下表所示**

| 阈值为0.9      |          | **实际的类别** |          |
| -------------- | -------- | -------------- | -------- |
|                |          | Positive       | Negative |
| **预测的类别** | Positive | 1              | 0        |
|                | Negative | 5              | 4        |

Precision = 1 / (1+ 0) = 1

Recall = 1 / (1 + 5) = 0.33

分析上述结果，可以得到以下结论：

+ 当系统将所有样本全部预测为正样本时（系统过于贪婪，预测值大等于0即为正样本），显然召回率可以达到最大，取值1，但是精确率将显著下降
+ 当设定很大的阈值（系统过分保守，预测值大等于0.9才是正样本），仅有一个正样本被预测正确，那么精确率的取值为1，但召回率将很低（`负样本被分为正类的概率降低，很多正样本被分类成负类`）

为了调和`Precision`与`Recall`的之间的矛盾，将引入F1指标来综合反映模型的性能：

​                            $\frac{2}{F1} = \frac{1}{Precision} + \frac{1}{Recall}$, $F1=\frac{2 * Prcision * Recall}{Prcision + Recall}$

此外，还有一个更通用的计算$F_\alpha$值得公式

 $F_\alpha=\frac{1+\alpha^2}{\alpha^2*Prcision + Recall}*Prcision * Recall$

当$\alpha=1$时，即为F1。