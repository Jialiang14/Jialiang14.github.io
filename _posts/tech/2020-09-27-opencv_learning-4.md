---

layout: post

title:opencv学习笔记(二)

category: 技术，opencv，C++

tag: React

keyword: React

---

## opncv 读书笔记（3）

## 描述和匹配兴趣点

198. 好的描述子要具有足够的独特性，能唯一地表示图像中地每个关键点。它还要有足够地鲁棒性，在照度变化或视角变动时仍能较好地体现同一批点集。理想地描述子还要简洁，以减少对内存地占用、提高计算效率。

199. *图像匹配是关键点的常用功能之一*，它的作用包括关联同一场景的两幅图像、检测图像中事务的发生地点。

200. 通过特征点匹配，可以将一幅图像的点集和另一幅图像（或一批图像）的点集关联起来。如果两个点集对应着现实世界中的同一场景元素，它们就应该是匹配的。

201. 比较图像块内像素的强度值来衡量两个正方形图像块的相似度，常见的方案是采用简单的**差的平方和**（Sum of Squared Differences, SSD）算法。

202. 图像分析中的一个常见任务是检测图像中是否存在特定的图像或物体。实现方法是把包含该物体的小图像作为模板，然后在指定图像上搜索与模板相似的部分。搜索的范围通常仅限于可能发现该物体的区域。在这个区域上滑动模板，并在每个像素位置计算相似度。

203. 特征描述子通常是一个N维的向量，在光照变化和拍摄角度发生微小扭曲时，它描述特征点的方式不会发生变化。通常可以用简单的差值矩阵来比较描述子，例如欧几里得距离。**特征描述子是一种非常强大的工具，能进行目标的匹配。**

204. 兴趣点描述子的计算结果是一个矩阵（即cv::Mat实例），矩阵的行数等于关键点容器的元素个数。每行是一个N维的描述子容器。SURF描述子的默认尺寸是64，而SIFT的默认尺寸是128。这个容器用于区分特征点周围的强度值图案。两个特征点越相似，它们的描述子容器就会越接近。SURF兴趣点并不一定要使用SURF描述子，SIFT也一样；**检测器和描述子可以任意搭配**。

205. 好的特征描述子不受照明和视角微小变动的影响，页不受图像中噪声的影响，因此它们通常基于局部强度值得差值。

206. 三种可以提高匹配质量的策略：

     + **交叉检查匹配项** 有一种简单的方法可以验证得到的匹配项，即重新进行同一个匹配过程，但在第二次匹配时，将第二幅图像的每个关键点逐个与第一幅图像的全部关键点进行比较。只有在两个方向都匹配了同一对关键点（即两个关键点互为最佳匹配）时，才认为是一个有效的匹配项。

       ```
       cv::BFMathcer matcher2(cv::NORM_L2,	// 度量距离 
       						true);		// 交叉检查标志
       ```

     + **比较检验法**， 若场景中相似的物体有很多时，一个关键点可以与多个其他关键点匹配。其中错误的匹配项非常多，最好能够把它们排除掉。为此我们需要维每个关键点找到两个最佳的匹配项，可以用cv::Descriptor Mathcer类的knnMatcher实现这个功能。

       ```
       // 为每个关键点找出两个最佳匹配项 
       std::vector<std::vector<cv::DMathc>> mathces;
       matcher.knnMatch(descriptors1, descriptor2,
       			matches, 2); // 找出k个最佳匹配项
       ```

     + **匹配差值的阈值化**， 还有一种更加简单的策略，就是把描述子之间差值太大的匹配项排除。

       ```
       // 指定范围的匹配
       float maxDist = 0.4;
       std::vector<std::vector<cv::DMatch>> matches2;
       matcher.radiusMatch(descriptor1, descriptor2, matches2, maxDist);
       // 两个描述子之间的最大允许差值
       ```

## 用二值图描述匹配关键点

207. 二值描述子一律使用Hamming规范
208. 因为OpenCV检测器和描述子具有泛型接口，所以二值描述子（例如ORB）的用法与SURF、SIFT没有什么区别。
209. ORB就是在BRIEF描述子的基础上构建的（前面介绍过BRIEF描述子），然后在关键点周围的邻域内随机选取一对像素点，创建一个二值描述子。比较这两个像素点的强度值，如果第一个点的强度值较大，就把对应描述子的位置（bit）设为1，否则就设为0。对一批随机像素点进行上述处理，就产生了一个由若干位（bit）组成的描述子，通常采用128到512位（成对地测试）。
210. **FREAK（Fast Retina Keypoint, 快速视网膜关键点）**，与BRISK一样，也是基于同心圆定义地采样模式。但为了设计描述子，设计者们使用人眼进行了类比。发现，随着离中央凹距离越来越远，视网膜上地神经节细胞密度越来越小。

## 估算图像之间的投影关系

211. 在实际应用中，图像坐标通常用像素值表示，而三维坐标通常用实际长度表示（例如用米作单位）。
212. 同一场景的两幅图像之间的投影关系。可以移动相机，从两个视角拍摄两幅照片；也可以使用两个相机，分别对同一个场景拍摄照片。如果两个相机被刚性基线分割，我们就称之为**立体视觉**。
213. 要根据图像中的一个点找到另一幅图像中对应的点，就需要在第二个成像平面上沿着这条线的投影搜索。这条虚线称为点x的**对极限**。它规定了两个对应点必须满足的基本条件，即对于一个点，在另一个视图中与它匹配的点必须位于它的对极线上，并且对极线的准确方向取决于两个相机的相对位置。
214. 一幅图像的极点位于所有对极限的交叉点，是另一个相机中心点的投影。注意，对极限的交叉点很可能（也经常）在图像边界的外面。
215. 如果想要精确地计算基础矩阵，匹配项的选择是很重要的。一般来说，匹配项要在整幅图像中均匀分布，并包含场景中不同深度的点，否则结果就会不稳定。尤其当所选场景点位于同一平面时，基础矩阵就会变差。
216. 所有对极限都穿过同一个点（极点）对矩阵产生了一个约束条件，这个约束条件把计算基础矩阵所需的匹配次数缩减到7次。
217. **用RANSAC（随机抽样一致性）算法匹配图像** 当用两个相机拍摄同一个场景时，会在不同的视角下看到相同的元素。
218. 在匹配两幅图像的特征点时，只接受位于对极线上的匹配项。若要判断是否满足这个条件，必须先知道基础矩阵，但计算基础矩阵又需要优质的匹配项。
219. 可以根据一些特征点匹配项计算图像对的基础矩阵。为了确保结果准确，采用的匹配项必须都是优质的。
220. RANSAC算法旨在根据一个可能包含大量局外项的数据集，估算一个特定的数学实体。其原理是从数据集中随机选取一些数据点，并仅用这些数据点进行估算。选取的数据点数量，应该是估算数学实体所需要的最小数量。对于基础矩阵，最小数量是8个匹配对（实际上只有7个，但是8个点的线性算法速度较快）。用着8个随机匹配对估算基础矩阵后，对剩下的全部匹配项进行测试，验证其是否满足根据这个矩阵得到的极线约束。标识出所有满足极线约束的匹配项（即特征点与对极限距离很近的匹配项），这些匹配项就组成了基础矩阵的支撑集。
221. RANSAC算法背后的核心思想是：支撑集越大，所计算矩阵正确的可能性就越大。反之，如果一个（或多个）随机选取的匹配项是错误的，那么计算得到的基础矩阵也是错误的，并且它的支撑集肯定会很小。反复执行这个过程，最后留下支撑集最大的矩阵作为最佳结果。
222. 提高最终匹配集的质量，必须要考虑以下三点：
     + 计算复杂度
     + 最终匹配项数量
     + 要得到仅包含准确匹配项的匹配集所需的可信度等级

223. **改进匹配项**。在双视图系统中，每个点肯定位于与它对应的点的对极线上。这就是基础矩阵表示的极线约束。因此，如果已经有了很准确的基础矩阵，就可以利用极线约束来更正得到的匹配项，具体做法是将强制匹配项置于它们的对极线上。使用OpenCV可以实现该功能：

     ```
     std::vector<cv::Point2f> newPoints1, newPoints2;
     // 改进匹配项
     correctMatches(fundamental,		// 基础矩阵
     				points1, points2,	// 原始位置
     				newPoints1, newPoints2);	// 新位置
     ```

     这个函数修改每个对应点的位置，从而在最小化累积（平方）位移时能满足极线约束。

224. 



